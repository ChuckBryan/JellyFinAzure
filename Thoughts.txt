You‚Äôre very close here‚Äîthe architecture is solid, and what‚Äôs biting you now is 90% shell + az behavior, not the design.

I‚Äôll do three things:

Call out where your current restore attempts are likely failing

Give you a drop-in, robust restore script for Revision 0000014 (individual blob download)

Recommend a slightly cleaner tar-based backup/restore you can switch to once things are stable

1. What‚Äôs (probably) going wrong right now
A. az storage blob list returns JSON, not blob names

Your ‚ÄúOption A‚Äù loop:

az storage blob list --prefix "$BACKUP_DIR/" | while read BLOB; do
  FILENAME=$(basename "$BLOB")
  az storage blob download --name "$BLOB" --file "/data/data/$FILENAME" --overwrite
done


Issues:

az storage blob list returns JSON objects, one big JSON array, not plain names.

while read BLOB is then reading arbitrary chunks of JSON, so:

basename "$BLOB" is garbage

az storage blob download --name "$BLOB" fails hard

Because your script likely has set -e (or exits on non-zero), the init container dies ‚Üí ContainerBackOff.

You need:

az storage blob list \
  --container-name "$CONTAINER" \
  --prefix "$BACKUP_DIR/" \
  --query "[].name" \
  -o tsv


That gives you just blob names (one per line), perfect for while read.

B. The ‚Äúglob is unreliable‚Äù problem is just shell semantics

From your failed attempts:

mv /data/data/$BACKUP_DIR/* /data/data/


Problems:

If the directory is empty, * expands to literal * ‚áí mv fails ‚áí script exits.

Hidden files (e.g. .jellyfin-data) are not matched by *. They stay behind.

In a set -e world, any failed mv/cp kills the init container.

So the ‚Äúglob is unreliable‚Äù is really:

nullglob / dotglob not set

No error guarding around commands that can legitimately fail

You‚Äôre right to move away from this and go to per-blob downloading. üëç

2. A robust restore script for Revision 0000014

Below is a self-contained restore script that:

Finds the latest backup folder by prefix (e.g. backup-20251108030217/)

Lists all blobs inside that folder

Downloads each blob and flattens it into /data/data/

Handles errors cleanly and logs progress

Verifies jellyfin.db exists before exiting

You can drop this in as the command for your restore-db init container.

Assumptions

You‚Äôre already handling auth exactly as you do in the backup sidecar:

Either via AZURE_STORAGE_ACCOUNT + AZURE_STORAGE_KEY or connection string

Or via Managed Identity + --auth-mode login

Environment variables (example names, adapt to your bicep):

BACKUP_CONTAINER=jellyfin-backups
BACKUP_PREFIX=backup-
MOUNT_PATH=/data/data

Script: restore-db.sh
#!/usr/bin/env bash
set -euo pipefail

echo "=== Jellyfin restore init container starting ==="

: "${BACKUP_CONTAINER:?BACKUP_CONTAINER not set}"
: "${BACKUP_PREFIX:=backup-}"
: "${MOUNT_PATH:=/data/data}"

# If you use MI-based auth, uncomment:
# echo "Logging into Azure with managed identity..."
# az login --identity --allow-no-subscriptions >/dev/null

echo "Looking for latest backup in container '$BACKUP_CONTAINER' with prefix '$BACKUP_PREFIX'..."

# 1. Find the latest backup directory by lastModified of *any file inside it*.
LATEST_BLOB=$(az storage blob list \
  --container-name "$BACKUP_CONTAINER" \
  --prefix "$BACKUP_PREFIX" \
  --include metadata \
  --query "max_by([], &properties.lastModified).name" \
  -o tsv)

if [ -z "${LATEST_BLOB:-}" ]; then
  echo "No backups found. Skipping restore; Jellyfin will start fresh."
  exit 0
fi

BACKUP_DIR="${LATEST_BLOB%%/*}"   # strip filename, keep 'backup-YYYYMMDDHHMMSS'
echo "Latest backup directory: $BACKUP_DIR (from blob: $LATEST_BLOB)"

# 2. Prepare mount path
mkdir -p "$MOUNT_PATH"

echo "Contents of $MOUNT_PATH before restore:"
ls -la "$MOUNT_PATH" || true

# Optional: clean only DB-related files (safer than rm -rf)
echo "Cleaning existing DB files (if any)..."
rm -f "$MOUNT_PATH"/jellyfin.db* || true
rm -f "$MOUNT_PATH"/.jellyfin* || true
rm -rf "$MOUNT_PATH"/playlists || true
rm -rf "$MOUNT_PATH"/ScheduledTasks || true
rm -rf "$MOUNT_PATH"/SQLiteBackups || true

# 3. List all blobs under that backup directory & download each one
echo "Listing blobs under prefix '$BACKUP_DIR/'..."
az storage blob list \
  --container-name "$BACKUP_CONTAINER" \
  --prefix "$BACKUP_DIR/" \
  --query "[].name" \
  -o tsv |
while IFS= read -r BLOB_NAME; do
  [ -z "$BLOB_NAME" ] && continue

  FILE_NAME="${BLOB_NAME##*/}"   # strip 'backup-.../' prefix
  TARGET_PATH="$MOUNT_PATH/$FILE_NAME"

  echo "Downloading blob '$BLOB_NAME' -> '$TARGET_PATH'..."
  az storage blob download \
    --container-name "$BACKUP_CONTAINER" \
    --name "$BLOB_NAME" \
    --file "$TARGET_PATH" \
    --overwrite \
    >/dev/null
done

echo "Contents of $MOUNT_PATH after restore:"
ls -la "$MOUNT_PATH"

# 4. Sanity check
if [ ! -f "$MOUNT_PATH/jellyfin.db" ]; then
  echo "ERROR: jellyfin.db not found after restore ‚Äì failing init container."
  exit 1
fi

echo "Found jellyfin.db ($(stat -c%s "$MOUNT_PATH/jellyfin.db") bytes)"
if [ -f "$MOUNT_PATH/jellyfin.db-wal" ]; then
  echo "Found jellyfin.db-wal ($(stat -c%s "$MOUNT_PATH/jellyfin.db-wal") bytes)"
fi

echo "=== Jellyfin restore completed successfully ==="
exit 0

How to wire this into the init container

If you‚Äôre using inline commands in Bicep / YAML, do something like:

initContainers:
  - name: restore-db
    image: mcr.microsoft.com/azure-cli
    command:
      - /bin/sh
      - -c
      - |
        chmod +x /scripts/restore-db.sh
        /scripts/restore-db.sh
    volumeMounts:
      - name: data-volume
        mountPath: /data/data
      - name: script-volume
        mountPath: /scripts
    env:
      - name: BACKUP_CONTAINER
        value: "jellyfin-backups"
      - name: BACKUP_PREFIX
        value: "backup-"
      - name: MOUNT_PATH
        value: "/data/data"
      # + your storage auth env vars


(If you‚Äôre not mounting a script volume and are just inlining the whole script in command:, you can paste the contents after -c.)

3. A cleaner long-term approach: tar the directory

Your intuitions in Option C are spot on. It simplifies everything:

Backup:
1 blob: backup-YYYYMMDDHHMMSS.tar.gz

Restore:
Download that blob ‚Üí tar -xzf into /data/data/ ‚Üí done.

You wrote:

Cons: Requires tar (not available in azure-cli image by default)

On most modern mcr.microsoft.com/azure-cli images, tar is there (Ubuntu based). If it isn‚Äôt in yours, you can either:

Use a tiny custom image (FROM mcr.microsoft.com/azure-cli + apt-get update && apt-get install -y tar), or

Use python -m tarfile (since azure-cli ships with Python)

Here‚Äôs what the tar-based backup & restore would look like.

Backup sidecar (tar version)
#!/usr/bin/env bash
set -euo pipefail

: "${BACKUP_CONTAINER:?BACKUP_CONTAINER not set}"
: "${DATA_PATH:=/data/data}"

TS=$(date +"%Y%m%d%H%M%S")
ARCHIVE="/tmp/jellyfin-backup-$TS.tar.gz"
BLOB_NAME="backup-$TS.tar.gz"

echo "Creating archive $ARCHIVE from $DATA_PATH..."
tar -czf "$ARCHIVE" -C "$DATA_PATH" .

echo "Uploading $ARCHIVE to container '$BACKUP_CONTAINER' as '$BLOB_NAME'..."
az storage blob upload \
  --container-name "$BACKUP_CONTAINER" \
  --name "$BLOB_NAME" \
  --file "$ARCHIVE" \
  --overwrite

echo "Backup complete: $BLOB_NAME"

Restore init container (tar version)
#!/usr/bin/env bash
set -euo pipefail

: "${BACKUP_CONTAINER:?BACKUP_CONTAINER not set}"
: "${MOUNT_PATH:=/data/data}"

echo "Looking for latest .tar.gz backup in '$BACKUP_CONTAINER'..."

LATEST_ARCHIVE=$(az storage blob list \
  --container-name "$BACKUP_CONTAINER" \
  --prefix "backup-" \
  --query "max_by([?ends_with(name, '.tar.gz')], &properties.lastModified).name" \
  -o tsv)

if [ -z "${LATEST_ARCHIVE:-}" ]; then
  echo "No .tar.gz backups found. Skipping restore."
  exit 0
fi

echo "Latest archive: $LATEST_ARCHIVE"

TMP_FILE="/tmp/jellyfin-restore.tar.gz"
mkdir -p "$(dirname "$TMP_FILE")" "$MOUNT_PATH"

echo "Downloading to $TMP_FILE..."
az storage blob download \
  --container-name "$BACKUP_CONTAINER" \
  --name "$LATEST_ARCHIVE" \
  --file "$TMP_FILE" \
  --overwrite

echo "Clearing old DB files..."
rm -f "$MOUNT_PATH"/jellyfin.db* || true
rm -f "$MOUNT_PATH"/.jellyfin* || true
rm -rf "$MOUNT_PATH"/playlists || true
rm -rf "$MOUNT_PATH"/ScheduledTasks || true
rm -rf "$MOUNT_PATH"/SQLiteBackups || true

echo "Extracting archive into $MOUNT_PATH..."
tar -xzf "$TMP_FILE" -C "$MOUNT_PATH"

echo "Contents after extract:"
ls -la "$MOUNT_PATH"

if [ ! -f "$MOUNT_PATH/jellyfin.db" ]; then
  echo "ERROR: jellyfin.db missing after tar restore"
  exit 1
fi

echo "Restore from archive complete."


This completely removes:

Blob prefix gymnastics

Directory flattening

Hidden file handling issues

‚Ä¶and plays very nicely with WAL mode as long as backups happen while Jellyfin is not actively mid-write (which in practice is usually fine; for the truly paranoid you could trigger a backup via a scheduled shutdown / restart cycle).

4. Observability tips for debugging the next revision

A couple of simple tricks to make the next failure (if any) much easier to diagnose:

Log streaming in ACA

az containerapp logs show \
  -n ca-jellyfin-uopr4dp2rx5jg \
  -g rg-jellyfin-eastus-uopr4dp2rx5jg \
  --type containerinit \
  --follow


That will show you the echo lines from the init container script in real time.

Never silently swallow errors

You‚Äôre already using set -euo pipefail ‚Äì that‚Äôs good. Just make sure any command that is allowed to fail is wrapped with || true.

Verify restore with exec

After a restart:

az containerapp exec \
  -n ca-jellyfin-uopr4dp2rx5jg \
  -g rg-jellyfin-eastus-uopr4dp2rx5jg \
  --command "ls -la /data/data/"


You should see:

jellyfin.db ~4KB

jellyfin.db-wal ~2‚Äì3MB

jellyfin.db-shm

.jellyfin-data, playlists/, etc.

If you wire in the per-blob restore script above for 0000014, that should get you past the ContainerBackOff and into the ‚Äúlogin screen instead of setup wizard‚Äù world.

If you‚Äôd like, I can also help you refactor your Bicep/YAML to include both the sidecar + init container definitions with these scripts inlined.